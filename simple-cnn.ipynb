{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384dc04d",
   "metadata": {
    "papermill": {
     "duration": 0.005034,
     "end_time": "2024-09-28T20:30:12.583658",
     "exception": false,
     "start_time": "2024-09-28T20:30:12.578624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# INSTALLING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64cbcdfd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-28T20:30:12.594569Z",
     "iopub.status.busy": "2024-09-28T20:30:12.594047Z",
     "iopub.status.idle": "2024-09-28T20:30:17.496840Z",
     "shell.execute_reply": "2024-09-28T20:30:17.495812Z"
    },
    "papermill": {
     "duration": 4.911078,
     "end_time": "2024-09-28T20:30:17.499277",
     "exception": false,
     "start_time": "2024-09-28T20:30:12.588199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in relevant libraries, and alias where appropriate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca304c7",
   "metadata": {
    "papermill": {
     "duration": 0.004291,
     "end_time": "2024-09-28T20:30:17.507923",
     "exception": false,
     "start_time": "2024-09-28T20:30:17.503632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOADING THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e4cd6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T20:30:17.517851Z",
     "iopub.status.busy": "2024-09-28T20:30:17.517383Z",
     "iopub.status.idle": "2024-09-28T20:30:22.857364Z",
     "shell.execute_reply": "2024-09-28T20:30:22.856461Z"
    },
    "papermill": {
     "duration": 5.347904,
     "end_time": "2024-09-28T20:30:22.859911",
     "exception": false,
     "start_time": "2024-09-28T20:30:17.512007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:01<00:00, 94870613.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Use transforms.compose method to reformat images for modeling,\n",
    "# and save to variable all_transforms for later use\n",
    "all_transforms = transforms.Compose([transforms.Resize((32,32)), # RESIZE THE IMAGES \n",
    "                                     transforms.ToTensor(), # CONVERTING THEM TO TENSORS\n",
    "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                                          std=[0.2023, 0.1994, 0.2010]) # IMAGE NORMALIZATION\n",
    "                                     ])\n",
    "# Create Training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                             train = True,\n",
    "                                             transform = all_transforms,\n",
    "                                             download = True)\n",
    "\n",
    "# Create Testing dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                            train = False,\n",
    "                                            transform = all_transforms,\n",
    "                                            download=True)\n",
    "\n",
    "# Instantiate loader objects to facilitate processing - ALLOWS US TO LOAD DATA IN BATCHES so as not to overwhelm our computing powers\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521099a",
   "metadata": {
    "papermill": {
     "duration": 0.006989,
     "end_time": "2024-09-28T20:30:22.873009",
     "exception": false,
     "start_time": "2024-09-28T20:30:22.866020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f3f2e6",
   "metadata": {
    "papermill": {
     "duration": 0.006381,
     "end_time": "2024-09-28T20:30:22.885783",
     "exception": false,
     "start_time": "2024-09-28T20:30:22.879402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For **nn.Conv2d** - we define the channels they receive (3 if they are RGB images), the channels they will return, and the kernel size\n",
    "\n",
    "for **nn.MaxPool2d** - max-pooling layer, it just requires the kernel size & stride\n",
    "\n",
    "for **nn.linear** - fully connected layer & **nn.ReLU** is an activation function used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b38cacb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T20:30:22.902698Z",
     "iopub.status.busy": "2024-09-28T20:30:22.901915Z",
     "iopub.status.idle": "2024-09-28T20:30:22.912453Z",
     "shell.execute_reply": "2024-09-28T20:30:22.911458Z"
    },
    "papermill": {
     "duration": 0.021437,
     "end_time": "2024-09-28T20:30:22.914757",
     "exception": false,
     "start_time": "2024-09-28T20:30:22.893320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a CNN class\n",
    "class ConvNeuralNet(nn.Module):\n",
    "#  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3de52",
   "metadata": {
    "papermill": {
     "duration": 0.008141,
     "end_time": "2024-09-28T20:30:22.929227",
     "exception": false,
     "start_time": "2024-09-28T20:30:22.921086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETTING HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68436b09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T20:30:22.943623Z",
     "iopub.status.busy": "2024-09-28T20:30:22.942965Z",
     "iopub.status.idle": "2024-09-28T20:30:23.231557Z",
     "shell.execute_reply": "2024-09-28T20:30:23.230567Z"
    },
    "papermill": {
     "duration": 0.298762,
     "end_time": "2024-09-28T20:30:23.234311",
     "exception": false,
     "start_time": "2024-09-28T20:30:22.935549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ConvNeuralNet(num_classes).to(device)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77741f9b",
   "metadata": {
    "papermill": {
     "duration": 0.00579,
     "end_time": "2024-09-28T20:30:23.246501",
     "exception": false,
     "start_time": "2024-09-28T20:30:23.240711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d8275d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T20:30:23.261268Z",
     "iopub.status.busy": "2024-09-28T20:30:23.260422Z",
     "iopub.status.idle": "2024-09-28T20:35:42.550224Z",
     "shell.execute_reply": "2024-09-28T20:35:42.549053Z"
    },
    "papermill": {
     "duration": 319.307834,
     "end_time": "2024-09-28T20:35:42.560796",
     "exception": false,
     "start_time": "2024-09-28T20:30:23.252962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.7663\n",
      "Epoch [2/20], Loss: 1.3774\n",
      "Epoch [3/20], Loss: 0.8064\n",
      "Epoch [4/20], Loss: 1.0771\n",
      "Epoch [5/20], Loss: 1.2523\n",
      "Epoch [6/20], Loss: 0.9002\n",
      "Epoch [7/20], Loss: 1.0478\n",
      "Epoch [8/20], Loss: 1.2560\n",
      "Epoch [9/20], Loss: 0.8017\n",
      "Epoch [10/20], Loss: 1.4000\n",
      "Epoch [11/20], Loss: 1.2817\n",
      "Epoch [12/20], Loss: 0.7695\n",
      "Epoch [13/20], Loss: 0.6671\n",
      "Epoch [14/20], Loss: 1.0705\n",
      "Epoch [15/20], Loss: 0.5806\n",
      "Epoch [16/20], Loss: 0.6427\n",
      "Epoch [17/20], Loss: 0.5489\n",
      "Epoch [18/20], Loss: 0.8282\n",
      "Epoch [19/20], Loss: 0.5758\n",
      "Epoch [20/20], Loss: 0.3980\n"
     ]
    }
   ],
   "source": [
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "for epoch in range(num_epochs):\n",
    "# Load in the data in batches using the train_loader object\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317048ab",
   "metadata": {
    "papermill": {
     "duration": 0.00825,
     "end_time": "2024-09-28T20:35:42.577501",
     "exception": false,
     "start_time": "2024-09-28T20:35:42.569251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f605bfdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T20:35:42.595960Z",
     "iopub.status.busy": "2024-09-28T20:35:42.595552Z",
     "iopub.status.idle": "2024-09-28T20:35:57.749305Z",
     "shell.execute_reply": "2024-09-28T20:35:57.748020Z"
    },
    "papermill": {
     "duration": 15.16583,
     "end_time": "2024-09-28T20:35:57.751660",
     "exception": false,
     "start_time": "2024-09-28T20:35:42.585830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 50000 train images: 83.106 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # THERE IS NO NEED TO CALCULATE GRADIENTS\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a7289",
   "metadata": {
    "papermill": {
     "duration": 0.007701,
     "end_time": "2024-09-28T20:35:57.767268",
     "exception": false,
     "start_time": "2024-09-28T20:35:57.759567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 349.271503,
   "end_time": "2024-09-28T20:35:59.097677",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-28T20:30:09.826174",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
