{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# INSTALLING LIBRARIES","metadata":{}},{"cell_type":"code","source":"# Load in relevant libraries, and alias where appropriate\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\n\n# Define relevant variables for the ML task\nbatch_size = 64\nnum_classes = 10\nlearning_rate = 0.001\nnum_epochs = 20\n\n# Device will determine whether to run the training on GPU or CPU.\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-28T13:29:19.231362Z","iopub.execute_input":"2024-09-28T13:29:19.232283Z","iopub.status.idle":"2024-09-28T13:29:19.238362Z","shell.execute_reply.started":"2024-09-28T13:29:19.232239Z","shell.execute_reply":"2024-09-28T13:29:19.237288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOADING THE DATASETS","metadata":{}},{"cell_type":"code","source":"# Use transforms.compose method to reformat images for modeling,\n# and save to variable all_transforms for later use\nall_transforms = transforms.Compose([transforms.Resize((32,32)), # RESIZE THE IMAGES \n                                     transforms.ToTensor(), # CONVERTING THEM TO TENSORS\n                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n                                                          std=[0.2023, 0.1994, 0.2010]) # IMAGE NORMALIZATION\n                                     ])\n# Create Training dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root = './data',\n                                             train = True,\n                                             transform = all_transforms,\n                                             download = True)\n\n# Create Testing dataset\ntest_dataset = torchvision.datasets.CIFAR10(root = './data',\n                                            train = False,\n                                            transform = all_transforms,\n                                            download=True)\n\n# Instantiate loader objects to facilitate processing - ALLOWS US TO LOAD DATA IN BATCHES so as not to overwhelm our computing powers\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                           batch_size = batch_size,\n                                           shuffle = True)\n\n\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                           batch_size = batch_size,\n                                           shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:29:19.240565Z","iopub.execute_input":"2024-09-28T13:29:19.241273Z","iopub.status.idle":"2024-09-28T13:29:20.820944Z","shell.execute_reply.started":"2024-09-28T13:29:19.241216Z","shell.execute_reply":"2024-09-28T13:29:20.820000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN ARCHITECTURE","metadata":{}},{"cell_type":"markdown","source":"For **nn.Conv2d** - we define the channels they receive (3 if they are RGB images), the channels they will return, and the kernel size\n\nfor **nn.MaxPool2d** - max-pooling layer, it just requires the kernel size & stride\n\nfor **nn.linear** - fully connected layer & **nn.ReLU** is an activation function used","metadata":{}},{"cell_type":"code","source":"# Creating a CNN class\nclass ConvNeuralNet(nn.Module):\n#  Determine what layers and their order in CNN object \n    def __init__(self, num_classes):\n        super(ConvNeuralNet, self).__init__()\n        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        \n        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        \n        self.fc1 = nn.Linear(1600, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, num_classes)\n    \n    # Progresses data across layers    \n    def forward(self, x):\n        out = self.conv_layer1(x)\n        out = self.conv_layer2(out)\n        out = self.max_pool1(out)\n        \n        out = self.conv_layer3(out)\n        out = self.conv_layer4(out)\n        out = self.max_pool2(out)\n                \n        out = out.reshape(out.size(0), -1)\n        \n        out = self.fc1(out)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:29:20.822354Z","iopub.execute_input":"2024-09-28T13:29:20.822871Z","iopub.status.idle":"2024-09-28T13:29:20.833544Z","shell.execute_reply.started":"2024-09-28T13:29:20.822821Z","shell.execute_reply":"2024-09-28T13:29:20.832572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SETTING HYPERPARAMETERS","metadata":{}},{"cell_type":"code","source":"model = ConvNeuralNet(num_classes).to(device)\n\n# Set Loss function with criterion\ncriterion = nn.CrossEntropyLoss()\n\n# Set optimizer with optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n\ntotal_step = len(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:33:03.743909Z","iopub.execute_input":"2024-09-28T13:33:03.744310Z","iopub.status.idle":"2024-09-28T13:33:03.756229Z","shell.execute_reply.started":"2024-09-28T13:33:03.744271Z","shell.execute_reply":"2024-09-28T13:33:03.755132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING THE MODEL","metadata":{}},{"cell_type":"code","source":"# We use the pre-defined number of epochs to determine how many iterations to train the network on\nfor epoch in range(num_epochs):\n# Load in the data in batches using the train_loader object\n    for i, (images, labels) in enumerate(train_loader):  \n        # Move tensors to the configured device\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:33:06.166620Z","iopub.execute_input":"2024-09-28T13:33:06.167026Z","iopub.status.idle":"2024-09-28T13:38:09.466075Z","shell.execute_reply.started":"2024-09-28T13:33:06.166987Z","shell.execute_reply":"2024-09-28T13:38:09.464992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TESTING THE MODEL","metadata":{}},{"cell_type":"code","source":"with torch.no_grad(): # THERE IS NO NEED TO CALCULATE GRADIENTS\n    correct = 0\n    total = 0\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:55:08.355658Z","iopub.execute_input":"2024-09-28T13:55:08.356096Z","iopub.status.idle":"2024-09-28T13:55:22.682670Z","shell.execute_reply.started":"2024-09-28T13:55:08.356057Z","shell.execute_reply":"2024-09-28T13:55:22.681657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}